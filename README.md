## ðŸŽ¬ Movie Recommendation System

Welcome to the Movie Recommendation System! This project is designed to provide personalized movie recommendations based on various metadata such as genres, keywords, cast, and crew. The system is built using Python and leverages several popular libraries to process the data and generate recommendations.

### ðŸš€ Features

- **Data Merging:** Combines data from multiple sources to create a comprehensive dataset.
- **Text Processing:** Cleans and processes textual data to ensure accurate recommendations.
- **Similarity Calculation:** Uses cosine similarity to find and recommend movies similar to a given title.
- **Easy to Use:** Simple function call to get recommendations.

### ðŸ“Š Data Sources

- **TMDB 5000 Credits Dataset:** Contains information about movie credits.
- **TMDB 5000 Movies Dataset:** Contains metadata for 5000 movies.

### Data Preprocessing

1. **Raw Data:**
   
   ![image](https://github.com/Aayu-1011/Movie-Recommendation/assets/134579511/57b6fe6f-3b43-4aca-ad01-4e0f17c082a4)

2. **Processed Data:**
   
   ![Screenshot 2024-06-08 151640](https://github.com/Aayu-1011/Movie-Recommendation/assets/134579511/0ffb2a60-ccb7-40b9-a7f1-0128751a65fd)

### Function for Recommendation

This function is the core of the recommendation system, using cosine similarity to find and suggest movies similar to a given title.

![Screenshot 2024-06-08 160417](https://github.com/Aayu-1011/Movie-Recommendation/assets/134579511/05140355-061c-4991-b56a-12d43482b053)

### Final Output

Here is an example of the output generated by the recommendation system.

![Screenshot 2024-06-08 152418](https://github.com/Aayu-1011/Movie-Recommendation/assets/134579511/f9a07ae1-710c-45ff-abdc-cd41fdd71748)

### Detailed Code Explanation

Here's a breakdown of the code used in the movie recommendation system:

```python #!/usr/bin/env python

import numpy as np
import pandas as pd

credits = pd.read_csv('tmdb_5000_credits.csv')
movies = pd.read_csv('tmdb_5000_movies.csv')

movies = movies.merge(credits, on='title')

# movie selecting criteria
# id
# genres
# keywords
# title
# overview
# cast 
# crew
movies = movies[['id','title' ,'overview' ,'genres','keywords','cast','crew']]

#  > for the further execution of recommendation system we creating a simple data set
#    which means we merging some of the columns like 'genres' , 'keywords' 'overview' , 'cast' , 'crew' and
#    after the merging we can say that tagline
#  > so basically our dataset have 3 column which are of ['id' , 'title' , 'tagline']

# now finding the missing data
movies.isnull().sum()
# then we fixing our missing data
movies.dropna(inplace=True)
movies.isnull().sum()

# now we check about duplicacy data
movies.duplicated().sum()

movies.iloc[0].genres



# now pre-processing this -->
# '[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]'
#     --> into
# ['Action','Adventure','Fantasy','Sci-Fi']


#        > creating an function for storing the values of pre-processing data


import ast

def convert(obj):
    L = []
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L


movies['genres'] = movies['genres'].apply(convert)

movies['keywords'] = movies['keywords'].apply(convert)


#  now lets come on the cast. so, in every movie have lot of cast members like main actor and side actors but for the
#  recommendation system we need to check only main character. And the main character of the movies is may be 3 name of the
#  movie of we just selecting the 3 main character of every movie 



def convert3(obj):
    L = []
    counter = 0
    for i in ast.literal_eval(obj):
        if (counter != 3):
            L.append(i['name'])
            counter += 1
        else:
            break
    return L


movies['cast'] = movies['cast'].apply(convert3)


#  > Now we fixing our crew, so everyone likes the movies of the specific crew we also say that according to "Director"
#    we selecting the movies

def fetch_director(obj):
    L = []
    for i in ast.literal_eval(obj):
        if i['job'] == 'Director':
            L.append(i['name'])
            break
    return L


movies['crew'] = movies['crew'].apply(fetch_director)


movies['overview'] = movies['overview'].apply(lambda x : x.split())

#    > now we removing the space between the 'genres', 'keywords', 'cast', 'crew'
#    > because suppose some wants the movie of 'tom holland' but our recommedated system doesnt understand due to
#      presence of 'tom cruise'.... so we removing the space for that



movies['genres'] = movies['genres'].apply(lambda x : [i.replace(" ",'') for i in x])


movies['keywords'].apply(lambda x : [i.replace(" ",'') for i in x])

movies['genres'] = movies['genres'].apply(lambda x : [i.replace(" ",'') for i in x])

movies['crew'] = movies['crew'].apply(lambda x : [i.replace(" ",'') for i in x])



movies['tagline'] = movies['genres'] + movies['overview'] + movies['keywords'] + movies['cast'] + movies['crew'] 

new_df = movies[['id' , 'title' , 'tagline']]
new_df.head()

#  'tagline' is a list so we conveting into string

new_df['tagline'] = new_df['tagline'].apply(lambda x:" ".join(x))




# so how to look our 'tagline'

new_df['tagline'][0]

new_df['tagline'] = new_df['tagline'].apply(lambda x: x.lower())


#  converting text into vectors
#     text --> vector
#  1). concatenating all the taglines 
#           tagline[0] + tagline[1] + tagline[2] + ....... 
#     and finding most frequent words (and we selecting maximum 5000 words)
#           w1|w2|w3|w4|w5|........|w5000
#  2). then finding the distance between the points in the graphical methods i.e. if we suggesting some movie then
#      we go to check the nearest point of the given point(what the suggested movie we need to pick)



from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000, stop_words = 'english')

#  > max_features = for maximum words which we selecting from tagline
#  > stop_words = for removing stop words from tagline like in,is,are,on


# CountVectorizer return the sparse matrix
# <4806x5000 sparse matrix of type '<class 'numpy.int64'>'
#   	with 161516 stored elements in Compressed Sparse Row format>
#  

# so we use numpy array for storing the value of tagline

cv.fit_transform(new_df['tagline']).toarray().shape



vectors = cv.fit_transform(new_df['tagline']).toarray()

cv.get_feature_names_out()
#     > then we facing some kind of issue like, somewhere we get 'action' and 'action' , so due to our 
#       recommendation system count differently both of them but the meaning of both are very much similar
 
#     > so we import a python library "nltk" nltk = is based on NLP
#     > we using nltk for resolving the issue with the help of "stem" function
#          stem = changes the words into root word
#              ['loved','loving','love'] ---> ['love','love','love']
        

import nltk
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)
new_df['tagline'] = new_df['tagline'].apply(stem)


#     > after using "stem" function
#     > so right now there is no issue of like 'action' or 'actions' , both are same, it is consider as single words

cv.get_feature_names_out()

#  for recommedation we finding the distance between the points, we have two option to finding the distance beteen point
#  1). by the Euclidean distance = it is the distance between the top-tip points of the lines.....so we cannot
#      use this method for finding the distance.
#  2). by "Cosine distance" = it is the distance by the angle between lines....so we using this method
#                             > if the angle is minimum between lines, it mean there is small distance
#                                 like '0 degree'
#                             > if the angle is large, it means there is large distance
#                                 like ' 90 degree'
#  so we using " Cosine Distance"

from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)

similarity.shape
# the meaning of (4806, 4806) ---> (distance the movie with other 4806 movies, distance the movie with other 4806 movies)
#  similarity[0] means ---> the similarity of the first movie with the first movie are exact same,
#  similarly with [1]  ---> the movie of second index is exact with second movie and have 
#                           differnt value for different movies

def recommend(movie):
    movie_index =  new_df[new_df['title'] == movie].index[0]
    distance = similarity[movie_index]
    movies_list = sorted(list(enumerate(distance)),reverse =True , key = lambda x: x[1])[1:6]
    
    for i in movies_list:
#        print(i[0])
        print(new_df.iloc[i[0]].title)

#                sorted(list(enumerate(similarity)),reverse =True , key = lambda x: x[1])
#     > for the recommendation we sortin our data based on the similarity...then we will see our data are gets sort
#       but we lose the position of the index (suppose 1 movie have similarity with index numer 2,6,109,500,1009),
#       then we use 'enumerate'
#     > enumerate gives an object then we using list function = list(enumerate(similarity))
#     > after solve the index problem we use 'sorted' function for sorting
#     > 'reverse' = for the decsending order we use revesre
#     > after sorting we see, our sorted list is sort on the basis of index.....but we need on the basis of similarity
#     > so we use 'lambda' function = lambda function tells the program to sort our data on basis of second feature 
#       which is similarity 
#     > and the similarity is the "Cosine" distance
#       so we
#         sorted(list(enumerate(distance)),reverse =True , key = lambda x: x[1])


#      > if we wants check the index then we simply use i[0]
#      > for the name of the movie we use " new_df.iloc[i[0]].title "
recommend('Avatar')

```

### Explanation

1. **Data Loading:** Load the movie and credits datasets using pandas.
2. **Data Merging:** Merge the datasets on the 'title' column to combine metadata and credits information.
3. **Text Preprocessing:** 
   - Convert JSON-like strings to lists using `ast.literal_eval`.
   - Extract relevant information from genres, keywords, cast, and crew.
   - Combine these features into a single 'tags' column.
4. **Text Normalization:**
   - Convert all text to lowercase.
   - Apply stemming using NLTK's PorterStemmer.
5. **Vectorization:** Convert the text data into numerical vectors using CountVectorizer.
6. **Similarity Calculation:** Compute cosine similarity between the vectors to measure similarity between movies.
7. **Recommendation Function:** Define a function to find and print the top 5 movies similar to the input movie title based on similarity scores.

This system effectively demonstrates a content-based approach to movie recommendation, leveraging natural language processing and cosine similarity to provide meaningful suggestions.
